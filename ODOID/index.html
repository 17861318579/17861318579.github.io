<html>
<head>
<style type="text/css">
body
{
	font-family: Arial;
}
</style>
</head>

<body>
<style type="text/css">
.mytable{
width:800px;
height:100px;
margin:0 auto;
border-collapse: collapse;

}
</style>

<table class="mytable" bordercolor="#EEEEE6" border="1">
  <tr>
    <th></th>
    <th><br> <h2 align="center">Dual-Path Attention based Network for Fundus Segmentation on OCT-Angiography
</h2></th>
	<td></td>
  </tr>
  
  <tr>
    <td></td>
    <td ><br>--------------------------------------------------------------------------------------------------------------------------------------------<br>
<br>  Dual-Path Attention Network (DPANet) model for segmentation.
<br>  Permission to use copy, or modify this dataset, tool and codes for educational and research purposes.
<br>  E-mail : mafei0603（at）163.com ; 17861318579（at）163.com 
<br>  Homepage : https://17861318579.github.io/ODOID
<br>--------------------------------------------------------------------------------------------------------------------------------------------<br><br> 
<b>1. Dataset Description </b>
<br> 
<p style=text-align:justify; text-justify:inter-ideograph;> 
Our constructed OpticDisc segmentation OCTA Image Dataset (ODOID), which was acquired by a SS-OCT (swept-source optical coherence tomography) system (VG200D, SVision Imaging, Ltd., Luoyang, Henan, China). 
<br>  Photos are captured by a 12 mm × 12 mm SS-OCT centered on the fovea in 288 Normal human eyes. We selected 50 OCTA images from these. To be private, we delete the information of volunteers, such as sex, name and age. The optic discs are labeled in the ODOID dataset.
<br>  All images are labeled by the ophthalmologist. The ophthalmologist labeled the retinal optic discs in the ODOID dataset.
<br>
</p>
</td>
	<td></td>
  </tr>
   <tr>
    <td></td>
	<td>
 
</td>
    <td>
	
</td>
  </tr>
   <tr>
    <td></td>
	
    <td><b>2. Code Download </b>
<br><br>
2.1  The <b> key code of our approach (DPANet) </b>for demo can be downloaded <a href="https://17861318579.github.io/LOID/DPA_Att_Module.py">here</a> (Pytorch).<br>    
<br>
2.4 The code of U-Net for demo can be downloaded <a href="https://17861318579.github.io/LOID/">here</a>  (Pytorch).
<br>
<br>
</td>
  <td>
	 
	</td>
	</tr>
	 <tr>
    <td></td>
	<td>
 <br><br>--------------------------------------------------------------------------------------------------------------------------------------------<br>
<h4 align="center">FIGURE 1 The thumbnail view of the ODOID Dataset</h4> <br>
<b>The Original Image </b>
<img src="image.jpg" width="800" />
<br>
<b>The Ground-truth of OD</b>
<img src="label.jpg" width="800" />
<br>
<br><br>--------------------------------------------------------------------------------------------------------------------------------------------<br>
<h4 align="center">.</h4> <br>

<br>

<br>
</td>
    <td>
	<a href="https://clustrmaps.com/site/1bobi"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=QoRYI9AoBD5uM3C9pbBm79T2pX0DSdkJY0iUGEq46eY&cl=ffffff" width="1" height="1" /></a>
</td>
  </tr>
</table>
 

</body>
</html>
